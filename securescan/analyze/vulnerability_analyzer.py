"""Vulnerability analyzer using Claude Opus 4.6.

Takes raw findings from static analysis and uses LLM reasoning to:
- Confirm or reject each finding
- Trace data flow from source to sink
- Assess severity and exploitability
- Provide detailed reasoning for each determination
"""

from __future__ import annotations

import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

from securescan.analyze.codebase_digest import CodebaseDigest
from securescan.analyze.opus_client import LLMResponse, OpusClient
from securescan.config import config
from securescan.detect.models import (
    EnrichedFinding,
    Exploitability,
    RawFinding,
    Severity,
)

logger = logging.getLogger(__name__)

ANALYSIS_SYSTEM_PROMPT = """\
You are a senior application security engineer performing a code audit.
You have deep expertise in identifying and explaining security vulnerabilities
in Python and JavaScript applications.

Your analysis must be:
- Precise: only flag genuine vulnerabilities, not theoretical risks
- Evidence-based: cite specific code lines and data flow paths
- Actionable: explain what's wrong and how to fix it

When analyzing a finding, trace the complete data flow from input source
to dangerous sink. Consider whether sanitization, validation, or framework
protections exist that would mitigate the issue.

Always respond with valid JSON matching the requested schema. No preamble
or explanation outside the JSON object."""


def _build_analysis_prompt(
    finding: RawFinding,
    digest: CodebaseDigest,
    repo_name: str,
) -> str:
    """Build the user prompt for vulnerability analysis."""

    finding_context = ""
    for section in digest.sections:
        if finding.file_path in section.heading:
            finding_context = section.content
            break

    if not finding_context:
        finding_context = finding.code_snippet

    return f"""\
Analyze this potential security vulnerability found in the repository "{repo_name}".

## Detection Details
- **Vulnerability Type:** {finding.vuln_type.value}
- **File:** {finding.file_path}
- **Lines:** {finding.line_start}-{finding.line_end}
- **Detection Method:** {finding.detection_method.value}
- **Rule:** {finding.rule_id or 'custom'}
- **Initial Assessment:** {finding.message}

## Code Context
{finding_context}

## Codebase Overview
{digest.sections[0].content if digest.sections else 'Not available'}

## Task
Determine whether this is a genuine vulnerability. Analyze:
1. Is there a real source of untrusted input flowing to this dangerous operation?
2. Does any sanitization, validation, or framework protection exist?
3. Is this code reachable from external input (HTTP request, CLI arg, file input)?
4. What is the realistic impact if exploited?

Respond ONLY with a JSON object in this exact schema:
{{
    "is_vulnerable": true or false,
    "confidence": 0.0 to 1.0,
    "severity": "critical" or "high" or "medium" or "low",
    "cvss_estimate": 0.0 to 10.0,
    "reasoning": "detailed explanation of your analysis",
    "taint_chain": "source -> transformation -> ... -> sink (or null if not vulnerable)",
    "exploitability": "confirmed" or "likely" or "possible" or "unlikely",
    "blast_radius": "description of what could be compromised",
    "is_reachable": true or false or null
}}"""


_SEVERITY_MAP = {
    "critical": Severity.CRITICAL,
    "high": Severity.HIGH,
    "medium": Severity.MEDIUM,
    "low": Severity.LOW,
}

_EXPLOITABILITY_MAP = {
    "confirmed": Exploitability.CONFIRMED,
    "likely": Exploitability.LIKELY,
    "possible": Exploitability.POSSIBLE,
    "unlikely": Exploitability.UNLIKELY,
}


def _fallback_enriched_finding(
    finding: RawFinding,
    reason: str,
) -> EnrichedFinding:
    """Build a conservative fallback when analysis is unavailable."""
    return EnrichedFinding(
        raw=finding,
        severity=Severity.MEDIUM,
        cvss_estimate=5.0,
        reasoning=reason,
        taint_chain=None,
        exploitability=Exploitability.POSSIBLE,
        blast_radius="Unknown - analysis failed",
        is_reachable=None,
    )


def _parse_analysis_response(
    finding: RawFinding,
    response: LLMResponse,
) -> EnrichedFinding | None:
    """Parse the LLM analysis response into an EnrichedFinding."""

    if not response.success or not response.json_data:
        logger.warning(
            f"LLM analysis failed for {finding.file_path}:{finding.line_start}: "
            f"{response.error or 'No JSON in response'}"
        )
        return _fallback_enriched_finding(
            finding,
            reason="LLM analysis unavailable - manual review recommended",
        )

    data = response.json_data

    if not data.get("is_vulnerable", True):
        logger.info(
            f"LLM rejected finding {finding.file_path}:{finding.line_start} - "
            f"not vulnerable ({data.get('reasoning', 'no reason given')[:100]})"
        )
        return None

    return EnrichedFinding(
        raw=finding,
        severity=_SEVERITY_MAP.get(data.get("severity", "medium"), Severity.MEDIUM),
        cvss_estimate=float(data.get("cvss_estimate", 5.0)),
        reasoning=data.get("reasoning", "No reasoning provided"),
        taint_chain=data.get("taint_chain"),
        exploitability=_EXPLOITABILITY_MAP.get(
            data.get("exploitability", "possible"), Exploitability.POSSIBLE
        ),
        blast_radius=data.get("blast_radius", "Unknown"),
        is_reachable=data.get("is_reachable"),
    )


def _analyze_single_finding(
    client: OpusClient,
    finding: RawFinding,
    digest: CodebaseDigest,
    repo_name: str,
) -> tuple[EnrichedFinding | None, float | str]:
    """Analyze a single finding and return parsed result with confidence."""
    prompt = _build_analysis_prompt(finding, digest, repo_name)
    response = client.analyze(
        system_prompt=ANALYSIS_SYSTEM_PROMPT,
        user_prompt=prompt,
        max_tokens=2048,
        temperature=0.0,
        expect_json=True,
    )

    result = _parse_analysis_response(finding, response)
    confidence = response.json_data.get("confidence", "?") if response.json_data else "?"
    return result, confidence


def analyze_findings(
    client: OpusClient,
    findings: list[RawFinding],
    digest: CodebaseDigest,
    repo_name: str,
    max_workers: int | None = None,
) -> list[EnrichedFinding]:
    """Analyze raw findings using Opus 4.6 semantic reasoning."""
    results: list[EnrichedFinding | None] = [None] * len(findings)
    rejected_count = 0

    logger.info(f"Analyzing {len(findings)} findings with Opus 4.6...")
    worker_count = max(1, max_workers or config.max_concurrent_llm_calls)

    with ThreadPoolExecutor(max_workers=worker_count) as executor:
        future_to_idx = {}
        for idx, finding in enumerate(findings):
            logger.info(
                f"  [{idx + 1}/{len(findings)}] {finding.vuln_type.value} in "
                f"{finding.file_path}:{finding.line_start}"
            )
            future = executor.submit(
                _analyze_single_finding,
                client,
                finding,
                digest,
                repo_name,
            )
            future_to_idx[future] = idx

        for future in as_completed(future_to_idx):
            idx = future_to_idx[future]
            finding = findings[idx]
            finding_id = f"[{finding.file_path}:{finding.line_start}]"

            try:
                result, confidence = future.result()
            except Exception as exc:
                logger.error(f"{finding_id} Analysis failed: {exc}")
                result = _fallback_enriched_finding(
                    finding,
                    reason=(
                        "LLM analysis unavailable due unexpected error - "
                        "manual review recommended"
                    ),
                )
                confidence = "?"

            results[idx] = result

            if result is not None:
                logger.info(
                    f"    {finding_id} -> {result.severity.value.upper()} "
                    f"(CVSS {result.cvss_estimate:.1f}, confidence {confidence})"
                )
            else:
                rejected_count += 1
                logger.info(f"    {finding_id} -> Rejected (not a real vulnerability)")

    enriched = [result for result in results if result is not None]

    logger.info(
        f"Analysis complete: {len(enriched)} confirmed, "
        f"{rejected_count} rejected out of {len(findings)} raw findings"
    )

    return enriched
